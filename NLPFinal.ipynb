{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vicky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vicky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vicky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vicky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://insights.blackcoffer.com/how-are-genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-ai-use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://insights.blackcoffer.com/benefits-of-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://insights.blackcoffer.com/how-big-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-ai-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0       1  https://insights.blackcoffer.com/how-is-login-...\n",
       "1       2  https://insights.blackcoffer.com/how-does-ai-h...\n",
       "2       3  https://insights.blackcoffer.com/ai-and-its-im...\n",
       "3       4  https://insights.blackcoffer.com/how-do-deep-l...\n",
       "4       5  https://insights.blackcoffer.com/how-artificia...\n",
       "5       6  https://insights.blackcoffer.com/how-are-genet...\n",
       "6       7  https://insights.blackcoffer.com/how-is-ai-use...\n",
       "7       8  https://insights.blackcoffer.com/benefits-of-b...\n",
       "8       9  https://insights.blackcoffer.com/how-big-data-...\n",
       "9      10  https://insights.blackcoffer.com/how-will-ai-m..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(r'C:\\Users\\vicky\\Downloads\\Input.xlsx')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Web Scraping Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-dfbf3fe5a399>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['TITLE'][i]=title.get_text()\n",
      "<ipython-input-4-dfbf3fe5a399>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CONTENT'][i]=content.get_text()\n"
     ]
    }
   ],
   "source": [
    "data['TITLE']=\"\"\n",
    "data['CONTENT']=\"\"\n",
    "for i in range(170):\n",
    "    url = data['URL'][i]\n",
    "    req = Request(url , headers={'User-Agent': 'Chrome/5.0'})\n",
    "\n",
    "    webpage = urlopen(req).read()\n",
    "    page_soup = soup(webpage, \"html.parser\")\n",
    "    title=page_soup.find(\"h1\",{\"class\":\"entry-title\"})\n",
    "    data['TITLE'][i]=title.get_text()\n",
    "    content=page_soup.find(\"div\",{\"class\":\"td-post-content\"})\n",
    "    data['CONTENT'][i]=content.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Title and Content Columns. Removing new lines and some other unnecessary characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ce57017fac5a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CONTENT'][i]=data['TITLE'][i]+data['CONTENT'][i]\n",
      "<ipython-input-5-ce57017fac5a>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CONTENT'][i]=data['CONTENT'][i].replace(\"\\n\", \". \")\n",
      "<ipython-input-5-ce57017fac5a>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CONTENT'][i]=data['CONTENT'][i].replace(\"\\xa0.\", \" \")\n"
     ]
    }
   ],
   "source": [
    "for i in range(170):\n",
    "    data['CONTENT'][i]=data['TITLE'][i]+data['CONTENT'][i]\n",
    "    data['CONTENT'][i]=data['CONTENT'][i].replace(\"\\n\", \". \")\n",
    "    data['CONTENT'][i]=data['CONTENT'][i].replace(\"\\xa0.\", \" \")\n",
    "data=data.drop('TITLE',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing any extra Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0efdebbc6c8b>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CONTENT'][j]=n\n"
     ]
    }
   ],
   "source": [
    "for j in range(170):\n",
    "    n=\"\"\n",
    "    h=False\n",
    "    for i in range(len(data['CONTENT'][j])):\n",
    "        if (h==False and data['CONTENT'][j][i]=='.'):\n",
    "            n+=data['CONTENT'][j][i]\n",
    "            h=True\n",
    "        elif (h==True and (data['CONTENT'][j][i]=='.' or data['CONTENT'][j][i]==' ')):\n",
    "            h=True\n",
    "        elif (h==True):\n",
    "            n+=\" \"\n",
    "            h=False\n",
    "        if (h==False):\n",
    "            n+=data['CONTENT'][j][i]\n",
    "    data['CONTENT'][j]=n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Cleaning the text in the review column\n",
    "data['CleanedContent'] = data['CONTENT'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POStagged']=\"\"\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "data['POStagged'] = data['CleanedContent'].apply(token_stop_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "data['Lemma'] = data['POStagged'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Cloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PositiveWords']=0\n",
    "data['NegativeWords']=0\n",
    "data['Polarity']=0\n",
    "data['Subjectivity']=0\n",
    "for j in range(170):\n",
    "    List=word_tokenize(data['Lemma'][j])\n",
    "    Positive=0\n",
    "    Negative=0\n",
    "    for i in range(len(List)):\n",
    "        if (TextBlob(List[i]).sentiment.polarity>0):\n",
    "            Positive+=1\n",
    "        elif (TextBlob(List[i]).sentiment.polarity<0):\n",
    "            Negative+=1\n",
    "    data.loc[j, 'PositiveWords']=Positive\n",
    "    data.loc[j, 'NegativeWords']=Negative\n",
    "    data.loc[j, 'Polarity'] = (Positive-Negative)/(Positive+Negative+0.000001)\n",
    "    data.loc[j, 'Subjectivity'] = (Positive+Negative)/(len(List)+0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(170):\n",
    "    sents = data['CONTENT'][i].split('.')\n",
    "    avg_len = sum(len(x.split()) for x in sents) / len(sents)\n",
    "    data.loc[i, 'AVG SENTENCE LENGTH']=avg_len\n",
    "    data.loc[i, 'AVG NUMBER OF WORDS PER SENTENCE']=avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PERCENTAGE OF COMPLEX WORDS']=0\n",
    "data['FOG INDEX']=0\n",
    "data['COMPLEX WORD COUNT']=0\n",
    "data['WORD COUNT']=0\n",
    "data['SYLLABLE PER WORD']=0\n",
    "data['PERSONAL PRONOUNS']=0\n",
    "for j in range(170):\n",
    "    totalSyllableCount=0\n",
    "    characters=0\n",
    "    count=0\n",
    "    ccount=0\n",
    "    List=word_tokenize(data['Lemma'][j])\n",
    "    for i in range(len(List)):\n",
    "        characters+=len(List[i])\n",
    "        n=syllable_count(List[i])\n",
    "        totalSyllableCount+=n\n",
    "        if (n>2):\n",
    "            ccount+=1\n",
    "        count+=1\n",
    "    data.loc[j, 'PERCENTAGE OF COMPLEX WORDS']=ccount/count\n",
    "    data.loc[j, 'FOG INDEX']=0.4*(data['AVG SENTENCE LENGTH'][j]+data['PERCENTAGE OF COMPLEX WORDS'][j])\n",
    "    data.loc[j, 'COMPLEX WORD COUNT']=ccount\n",
    "    data.loc[j, 'WORD COUNT']=count\n",
    "    data.loc[j, 'SYLLABLE PER WORD']=totalSyllableCount/len(List)   \n",
    "    data.loc[j, 'AVG WORD LENGTH']=characters/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(170):\n",
    "    personalPronoun=0\n",
    "    List=word_tokenize(data['CONTENT'][j])\n",
    "    for i in range(len(List)):\n",
    "        if ((List[i].lower()=='i' or List[i].lower()=='we' or List[i].lower()=='us' or List[i].lower()=='my' or List[i].lower()=='ours') and List[i]!='US'):\n",
    "            personalPronoun+=1\n",
    "    data.loc[j, 'PERSONAL PRONOUNS']=personalPronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.rename(columns={'PositiveWords':'POSITIVE SCORE','NegativeWords':'NEGATIVE SCORE','Polarity':'POLARITY SCORE','Subjectivity':'SUBJECTIVITY SCORE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['CONTENT','CleanedContent','POStagged','Lemma'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.076212</td>\n",
       "      <td>20.222222</td>\n",
       "      <td>20.222222</td>\n",
       "      <td>0.226328</td>\n",
       "      <td>8.179420</td>\n",
       "      <td>98</td>\n",
       "      <td>433</td>\n",
       "      <td>1.939954</td>\n",
       "      <td>4</td>\n",
       "      <td>6.143187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>20.062500</td>\n",
       "      <td>20.062500</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>8.138402</td>\n",
       "      <td>110</td>\n",
       "      <td>388</td>\n",
       "      <td>2.095361</td>\n",
       "      <td>2</td>\n",
       "      <td>6.458763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.084316</td>\n",
       "      <td>19.287234</td>\n",
       "      <td>19.287234</td>\n",
       "      <td>0.293744</td>\n",
       "      <td>7.832391</td>\n",
       "      <td>324</td>\n",
       "      <td>1103</td>\n",
       "      <td>2.097915</td>\n",
       "      <td>13</td>\n",
       "      <td>6.413418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.083650</td>\n",
       "      <td>26.411765</td>\n",
       "      <td>26.411765</td>\n",
       "      <td>0.300380</td>\n",
       "      <td>10.684858</td>\n",
       "      <td>79</td>\n",
       "      <td>263</td>\n",
       "      <td>2.152091</td>\n",
       "      <td>1</td>\n",
       "      <td>6.673004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>17.956522</td>\n",
       "      <td>17.956522</td>\n",
       "      <td>0.294366</td>\n",
       "      <td>7.300355</td>\n",
       "      <td>209</td>\n",
       "      <td>710</td>\n",
       "      <td>2.043662</td>\n",
       "      <td>27</td>\n",
       "      <td>6.242254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0       1  https://insights.blackcoffer.com/how-is-login-...              23   \n",
       "1       2  https://insights.blackcoffer.com/how-does-ai-h...              28   \n",
       "2       3  https://insights.blackcoffer.com/ai-and-its-im...              62   \n",
       "3       4  https://insights.blackcoffer.com/how-do-deep-l...              12   \n",
       "4       5  https://insights.blackcoffer.com/how-artificia...              35   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              10        0.393939            0.076212            20.222222   \n",
       "1               4        0.750000            0.082474            20.062500   \n",
       "2              31        0.333333            0.084316            19.287234   \n",
       "3              10        0.090909            0.083650            26.411765   \n",
       "4              23        0.206897            0.081690            17.956522   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                         20.222222                     0.226328   8.179420   \n",
       "1                         20.062500                     0.283505   8.138402   \n",
       "2                         19.287234                     0.293744   7.832391   \n",
       "3                         26.411765                     0.300380  10.684858   \n",
       "4                         17.956522                     0.294366   7.300355   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                  98         433           1.939954                  4   \n",
       "1                 110         388           2.095361                  2   \n",
       "2                 324        1103           2.097915                 13   \n",
       "3                  79         263           2.152091                  1   \n",
       "4                 209         710           2.043662                 27   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         6.143187  \n",
       "1         6.458763  \n",
       "2         6.413418  \n",
       "3         6.673004  \n",
       "4         6.242254  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incase you want to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data.to_csv('COntentOooonly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
